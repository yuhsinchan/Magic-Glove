{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from eval import NMSLTestDataset, Classifier\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LM\n",
    "df_LM = pd.read_csv(\"./bigram.csv\")\n",
    "LM = {row[\"word\"].upper(): row[\"prob\"] for i, row in df_LM.iterrows()}\n",
    "\n",
    "# load dict\n",
    "df_dict = pd.read_csv(\"./unigram_freq.csv\")\n",
    "dictionary = df_dict[\"word\"][:500]\n",
    "dictionary = set(dictionary)\n",
    "dictionary.add(\"dog\")\n",
    "dictionary.add(\"apple\")\n",
    "dictionary.add(\"shit\")\n",
    "dictionary.add(\"fuck\")\n",
    "\n",
    "matrix = []\n",
    "dict_list = []\n",
    "for i in dictionary:\n",
    "    vector = [0 for _ in range(26)]\n",
    "    for c in i:\n",
    "        vector[ord(c) - ord(\"a\")] += 1\n",
    "    matrix.append(vector)\n",
    "    dict_list.append(i)\n",
    "matrix_tensor = torch.tensor(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv1d(8, 10, kernel_size=(3,), stride=(1,))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=27, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = NMSLTestDataset(\"../dataset/test/\", \"dog.txt\")\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "model = Classifier()\n",
    "model.load_state_dict(torch.load(\"./models/model_unnorm.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.tensor([[0 for i in range(27)] for j in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(last_topN, topN, N):\n",
    "    last_vector = torch.zeros((27))\n",
    "    for i in last_topN:\n",
    "        last_vector[i] = 1\n",
    "    \n",
    "    this_vector = torch.zeros((27))\n",
    "    for i in topN:\n",
    "        this_vector[i] = 1\n",
    "    \n",
    "    # print(last_vector, this_vector)\n",
    "    \n",
    "    return torch.sum(torch.mul(last_vector, this_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(matrix, word):\n",
    "    word_vector = [0 for i in range(26)]\n",
    "    for i in word:\n",
    "        word_vector[ord(i) - ord(\"A\")] += 1\n",
    "    word_vector = torch.tensor(word_vector)\n",
    "    \n",
    "    score = []\n",
    "    for v in matrix:\n",
    "        score.append(torch.sum(torch.mul(v, word_vector)) / max(torch.sum(v), len(word)))\n",
    "    \n",
    "    score = torch.tensor(score)\n",
    "    return torch.argsort(score, descending=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def DTW(recog, ref):\n",
    "    table = np.zeros((len(recog), len(ref)))\n",
    "    \n",
    "    table[0, 0] = int(recog[0] != ref[0])\n",
    "    # init the first row\n",
    "    for i in range(1, table.shape[0]):\n",
    "        table[i, 0] = int(recog[i] != ref[0]) + table[i-1, 0]\n",
    "        \n",
    "    # init the first col\n",
    "    for i in range(1, table.shape[1]):\n",
    "        table[0, i] = int(recog[0] != ref[i]) + table[0, i-1]\n",
    "        \n",
    "    for i in range(1, table.shape[0]):\n",
    "        for j in range(1, table.shape[1]):\n",
    "            table[i, j] = min(table[i-1, j] + 1,\n",
    "                              table[i, j-1] + 1,\n",
    "                              table[i-1, j-1] + int(recog[i] != ref[j]))\n",
    "    \n",
    "    # print(table)\n",
    "    return table[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTW(\"aplee\", \"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[\tJ\tM\t\n",
      "12\n",
      "D\tZ\tH\t\n",
      "10\n",
      "T\tZ\tD\t\n",
      "9\n",
      "O\tS\tE\t\n",
      "16\n",
      "F\tG\tJ\t\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "N = 3\n",
    "\n",
    "count = 0\n",
    "\n",
    "last_topN = []\n",
    "last_topN_prob = []\n",
    "table = {}\n",
    "\n",
    "avg_score = 0\n",
    "\n",
    "for batch in test_loader:\n",
    "    inputs, _ = batch\n",
    "    \n",
    "    output_res = model.fc[0](model.cnn[0](inputs).view(-1))\n",
    "    # output_res = model(inputs)\n",
    "    score[cnt % 5] = output_res\n",
    "    \n",
    "    cnt += 1\n",
    "    if cnt < 5:\n",
    "        continue\n",
    "    \n",
    "    # avg_score = (torch.sum(score, dim = 0) / 5) + avg_score / 2\n",
    "    avg_score = F.softmax(output_res)\n",
    "    \n",
    "    topN = torch.argsort(avg_score, descending = True)[:N]\n",
    "    topN_prob = torch.sort(avg_score, descending = True)[0][:N]\n",
    "    \n",
    "    match = compare(last_topN, topN, N)\n",
    "    # print(topN, match)\n",
    "    \n",
    "    # print(match)\n",
    "    \n",
    "    if match >= N:\n",
    "        count += 1\n",
    "    elif count > 5:\n",
    "        print(count)\n",
    "        line = \"\"\n",
    "        for i in last_topN:\n",
    "            line += chr(ord(\"A\") + i) + \"\\t\"\n",
    "            \n",
    "        if table == {}:\n",
    "            for i, c in enumerate(last_topN):\n",
    "                if c == 26:\n",
    "                    char = \" \"\n",
    "                else:\n",
    "                    char = chr(ord(\"A\") + c)\n",
    "                table[char] = LM[f\" {char}\"] * last_topN_prob[i]\n",
    "        else:\n",
    "            tmp_table = {}\n",
    "            for i, c in enumerate(last_topN):\n",
    "                if c == 26:\n",
    "                    # char = \" \"\n",
    "                    continue\n",
    "                else:\n",
    "                    char = chr(ord(\"A\") + c)\n",
    "                this_seq = \"\"\n",
    "                this_prob = -1\n",
    "                \n",
    "                for s, p in table.items():\n",
    "                        # print(this_seq, s, p)\n",
    "                    if p * LM[s[-1] + char] * last_topN_prob[i] > this_prob:\n",
    "                        this_seq = s + char\n",
    "                        this_prob = p * LM[s[-1] + char] * last_topN_prob[i]\n",
    "\n",
    "                    # print(char, s, this_seq, this_prob)\n",
    "                tmp_table[this_seq] = this_prob\n",
    "            \n",
    "            table = tmp_table\n",
    "        \n",
    "        print(line)\n",
    "        count = 0\n",
    "    else:\n",
    "        count = 0\n",
    "        \n",
    "        \n",
    "\n",
    "    last_topN = topN\n",
    "    last_topN_prob = topN_prob\n",
    "    \n",
    "    # print(match)\n",
    "    \n",
    "    # line = \"\"\n",
    "    # for i in topN:\n",
    "    #     line += chr(ord(\"A\") + i) + \"\\t\"\n",
    "    \n",
    "    # print(line)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-26971.9102,  -2471.3215,   7241.4780, -21668.5117, -39232.0859,\n",
       "         11284.2695,  32233.6465,  -4176.1074,  11352.4482,  57395.9648,\n",
       "         26173.9180,   9954.7021,  55054.1172,   5895.0137, -10717.1680,\n",
       "          7016.1040, -39109.5820, -25625.5762, -26987.9492, -37922.9531,\n",
       "        -30904.9141, -15302.6719,   1508.2080,   7213.1768,   9834.4863,\n",
       "         13818.2129,  51524.5117], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MHTOF': tensor(59655624., grad_fn=<MulBackward0>),\n",
       " 'MDDEG': tensor(18099652., grad_fn=<MulBackward0>),\n",
       " 'MHTOJ': tensor(1492542.3750, grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('photos', 0.5)\n",
      "{'photo': 0.4, 'photos': 0.5, 'them': 0.0, 'total': 0.2, 'most': 0.0, 'that': 0.0, 'home': 0.0, 'hot': 0.0, 'both': 0.0, 'forum': 0.0, 'off': -0.3333333333333333, 'from': 0.0, 'too': 0.0, 'hotel': 0.2, 'form': -0.25, 'room': 0.0, 'other': 0.0, 'yahoo': 0.2, 'food': 0.0, 'south': 0.0}\n"
     ]
    }
   ],
   "source": [
    "word = list(table.keys())[0]\n",
    "# word = \"APLE\"\n",
    "tops = sim(matrix_tensor, word)\n",
    "\n",
    "scores = {}\n",
    "for i in tops:\n",
    "    scores[dict_list[i]] = (len(dict_list[i]) - \n",
    "                            DTW(word.lower(), dict_list[i])) / len(dict_list[i])\n",
    "\n",
    "max_pair = (\"\", -1)\n",
    "\n",
    "for key, val in scores.items():\n",
    "    if val > max_pair[1]:\n",
    "        max_pair = (key, val)\n",
    "\n",
    "print(max_pair)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTW(\"results\", \"APRLLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_res = model.fc[0](model.cnn[0](inputs).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-53942.9102,  -4942.3213,  14482.4785, -43336.5117, -78464.0859,\n",
       "         22568.2695,  64466.6484,  -8352.1074,  22704.4492, 114790.9688,\n",
       "         52346.9180,  19908.7031, 110108.1172,  11790.0137, -21434.1680,\n",
       "         14032.1035, -78218.5781, -51250.5781, -53974.9492, -75844.9531,\n",
       "        -61808.9141, -30604.6719,   3016.2080,  14426.1768,  19668.4863,\n",
       "         27636.2129, 103048.5156], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0] + output_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 12, 26,  6, 10, 25,  8,  5, 11, 24,  2, 23, 15, 13, 22,  1,  7, 14,\n",
       "        21,  3, 17,  0, 18, 20, 19, 16,  4])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(avg_score, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(ord(\"A\") + 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-26971.9102,  -2471.3215,   7241.4780, -21668.5117, -39232.0859,\n",
       "         11284.2695,  32233.6465,  -4176.1074,  11352.4482,  57395.9648,\n",
       "         26173.9180,   9954.7021,  55054.1172,   5895.0137, -10717.1680,\n",
       "          7016.1040, -39109.5820, -25625.5762, -26987.9492, -37922.9531,\n",
       "        -30904.9141, -15302.6719,   1508.2080,   7213.1768,   9834.4863,\n",
       "         13818.2129,  51524.5117], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flatten' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/yuhsinchan/Documents/dclab_2022_fall/final/python/eval.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22646f726d4465736b746f70227d/home/yuhsinchan/Documents/dclab_2022_fall/final/python/eval.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mcnn[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mweight\n",
      "File \u001b[0;32m~/anaconda3/envs/general_slu/lib/python3.10/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flatten' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "model.cnn[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256\n",
    "\n",
    "00000100 00000010 00010101"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('general_slu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5661c73bf5f4ce6179e3148e3c825b6832fd4cb82045a10b114db5b9548c77c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
