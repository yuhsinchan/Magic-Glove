{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuhsinchan/anaconda3/envs/general_slu/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from eval_quantize import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuhsinchan/anaconda3/envs/general_slu/lib/python3.10/site-packages/torch/ao/quantization/observer.py:176: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_fp32 = Classifier()\n",
    "model_fp32.eval()\n",
    "\n",
    "model_fp32.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "model_fp32_fused = torch.quantization.fuse_modules(\n",
    "    model_fp32, [[\"conv\", \"batchnorm\"]]\n",
    ")\n",
    "model_fp32_prepared = torch.quantization.prepare(model_fp32_fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32_prepared.load_state_dict(torch.load(\"model_quantize.pth\"))\n",
    "\n",
    "model_int8 = torch.quantization.convert(model_fp32_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (quant): Quantize(scale=tensor([0.0673]), zero_point=tensor([58]), dtype=torch.quint8)\n",
       "  (conv): QuantizedConv1d(8, 10, kernel_size=(3,), stride=(1,), scale=5.970702171325684, zero_point=72)\n",
       "  (batchnorm): Identity()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): QuantizedLinear(in_features=30, out_features=27, scale=1740.132568359375, zero_point=45, qscheme=torch.per_channel_affine)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('quant.scale', tensor([0.0673])),\n",
       "             ('quant.zero_point', tensor([58])),\n",
       "             ('conv.weight',\n",
       "              tensor([[[ 29.8405,  15.0377,  27.4908],\n",
       "                       [  4.9343,   0.4699,   8.2238],\n",
       "                       [-26.0811,   9.8685,  -9.1636],\n",
       "                       [ 11.0433,   3.2895,   5.6391],\n",
       "                       [  6.1091,   1.6448,   0.7049],\n",
       "                       [-20.2069, -15.5077, -13.3930],\n",
       "                       [ 15.9776,  15.5077,  13.8629],\n",
       "                       [ -9.6335,  -7.5189,  -9.1636]],\n",
       "              \n",
       "                      [[ 14.2402,  13.5829,  10.2967],\n",
       "                       [ 13.8020, -16.8691,  -0.2191],\n",
       "                       [ 27.8231,  -1.5336,  19.9362],\n",
       "                       [-12.4875,  -0.8763, -10.2967],\n",
       "                       [ -9.8586,  -0.4382,   1.5336],\n",
       "                       [-13.3638,  -7.6678,  -9.2013],\n",
       "                       [-16.8691, -15.3356, -20.5935],\n",
       "                       [ 10.5158,  11.3921,  12.2684]],\n",
       "              \n",
       "                      [[  6.0615,   5.7860,   1.9287],\n",
       "                       [ 20.9397,   1.6531,  19.8377],\n",
       "                       [ 20.1132,  -3.3063,   5.2349],\n",
       "                       [-22.0418, -14.8782, -23.1439],\n",
       "                       [ 33.8893,  34.4404,  34.9914],\n",
       "                       [-23.1439, -21.4908, -25.0726],\n",
       "                       [ -1.1021,   0.2755,  -4.6839],\n",
       "                       [  1.9287,   4.6839,   0.2755]],\n",
       "              \n",
       "                      [[  8.6687,   8.0984,  -9.0108],\n",
       "                       [  2.9656, -13.2311,  -2.8515],\n",
       "                       [ -3.0797,  10.2655,   1.2547],\n",
       "                       [  2.9656,  -1.2547,   3.0797],\n",
       "                       [ 14.4858,  11.2921,  11.8624],\n",
       "                       [ -9.9233,  -9.8093,  -8.6687],\n",
       "                       [  4.7906,   2.0531,  10.6077],\n",
       "                       [ 10.1515,   2.1672,  -2.3953]],\n",
       "              \n",
       "                      [[-20.8690, -11.7955, -30.2450],\n",
       "                       [ -2.4196,  -6.6539,  -8.4686],\n",
       "                       [ 17.2396,   8.7710,  20.5666],\n",
       "                       [  2.4196,  -6.3514,   3.6294],\n",
       "                       [  3.0245,   0.3024,   3.9318],\n",
       "                       [ 38.4111,  37.2013,  37.2013],\n",
       "                       [-30.5474, -27.8254, -26.3131],\n",
       "                       [ -3.3269,  -2.4196, -11.1906]],\n",
       "              \n",
       "                      [[  5.9877,  -3.8630,  -4.0562],\n",
       "                       [ -5.6014,  -7.7260,  -3.0904],\n",
       "                       [ -2.1247,   0.9658,  13.1342],\n",
       "                       [ -7.3397,  -1.9315, -11.3959],\n",
       "                       [ -2.8973,  -5.2151,  -9.0781],\n",
       "                       [  3.6699,  -5.0219,  -4.4425],\n",
       "                       [ 22.0191,  11.3959,  14.2931],\n",
       "                       [ 19.8945,  10.4301,  24.5301]],\n",
       "              \n",
       "                      [[ 34.5033,  32.3299,  33.9599],\n",
       "                       [ 20.1043,  -0.2717,  14.9424],\n",
       "                       [ 17.9309,   8.1504,   6.7920],\n",
       "                       [  7.0637,  -1.9018,   2.7168],\n",
       "                       [ -5.4336,  -9.7805, -10.0521],\n",
       "                       [ 11.9539,  15.2141,  15.4857],\n",
       "                       [ -9.7805,  -4.3469,  -4.3469],\n",
       "                       [ -5.7053,  -7.8787, -14.6707]],\n",
       "              \n",
       "                      [[ 28.4904,  28.2216,  34.1347],\n",
       "                       [  0.2688,   0.5376, -14.7828],\n",
       "                       [  5.3755,   2.1502,   6.7194],\n",
       "                       [-16.9330,  -7.5258, -11.0199],\n",
       "                       [-22.0397, -21.7710, -24.1900],\n",
       "                       [ 34.1347,  32.5221,  33.8659],\n",
       "                       [  9.9448,   3.4941,   9.4072],\n",
       "                       [ -0.5376,  -1.0751,  15.3203]],\n",
       "              \n",
       "                      [[-25.8161, -24.6098, -30.8829],\n",
       "                       [ -6.2731,  -0.2413, -12.0636],\n",
       "                       [  0.9651,   7.9620,  13.0287],\n",
       "                       [ -6.7556,  -0.7238, -10.6160],\n",
       "                       [-23.6447, -21.9558, -25.3336],\n",
       "                       [  9.4096,   8.9271,   7.4794],\n",
       "                       [ -4.5842,  -6.0318,  -2.1715],\n",
       "                       [ -6.5144,  -5.3080,  -4.5842]],\n",
       "              \n",
       "                      [[-15.7177, -15.7177, -26.8126],\n",
       "                       [ 16.4112,   2.3114,  15.7177],\n",
       "                       [-11.0949,  -5.3163, -13.8686],\n",
       "                       [ -6.2409,   0.4623,  -2.7737],\n",
       "                       [-11.3260, -14.7932, -18.2603],\n",
       "                       [ 11.7883,   2.7737,   3.9294],\n",
       "                       [  3.9294,  -3.9294,   8.7834],\n",
       "                       [ 29.3552,  14.5620,  25.6569]]], size=(10, 8, 3), dtype=torch.qint8,\n",
       "                     quantization_scheme=torch.per_channel_affine,\n",
       "                     scale=tensor([0.2350, 0.2191, 0.2755, 0.1141, 0.3024, 0.1932, 0.2717, 0.2688, 0.2413,\n",
       "                      0.2311], dtype=torch.float64),\n",
       "                     zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), axis=0)),\n",
       "             ('conv.bias',\n",
       "              Parameter containing:\n",
       "              tensor([ -2.9764,  24.5993,  36.4767, -23.1963,  15.9849,  15.9581, -13.9785,\n",
       "                        9.2169, -15.3853, -30.7348], requires_grad=True)),\n",
       "             ('conv.scale', tensor(5.9707)),\n",
       "             ('conv.zero_point', tensor(72)),\n",
       "             ('linear.scale', tensor(1740.1326)),\n",
       "             ('linear.zero_point', tensor(45)),\n",
       "             ('linear._packed_params.dtype', torch.qint8),\n",
       "             ('linear._packed_params._packed_params',\n",
       "              (tensor([[ 27.1275,  29.5659,  33.8332, -16.7642, -14.9354, -14.0209,  38.7100,\n",
       "                         38.1004,  38.7100,  31.0899,  30.4803,  28.9563,   9.1441,  -7.3153,\n",
       "                        -12.4969,  28.9563,  18.2882,  15.5450,   4.8769,   5.1817,   5.4865,\n",
       "                          8.8393,  10.9729,  10.0585,  -7.0105,  -5.7913,  -6.4009,  25.6035,\n",
       "                         21.6410,  24.0795],\n",
       "                       [ 13.1471,   3.9162,  -5.5945,   6.7134,  10.6296,  14.5457, -35.5252,\n",
       "                        -34.1266, -35.8049,   6.4337,   7.5526,  18.1822,   3.0770,   1.1189,\n",
       "                          7.5526, -29.9307, -27.9726, -27.4131,  28.5320,  27.1334,  29.9307,\n",
       "                        -33.5671, -29.3712, -27.9726,  17.0633,  20.6997,  27.4131,  -4.7553,\n",
       "                         -4.1959,  -7.8323],\n",
       "                       [-26.3711, -27.2127, -35.9095,   9.8190,   4.7692,  14.5883,  16.2715,\n",
       "                         14.3077,  14.3077,   5.3303,  -8.9774,   5.3303,  30.0181,  31.7014,\n",
       "                         33.6652,  15.1493,   7.8552,  11.2217,  11.2217,  -1.1222,   1.1222,\n",
       "                         19.6380,  15.9910,  22.4435, -12.0634, -17.9548,  -7.2941, -14.3077,\n",
       "                        -27.4932, -23.0046],\n",
       "                       [-26.2048, -31.0801, -28.0331, -38.6978, -35.9555, -37.7837, -38.6978,\n",
       "                        -37.4790, -38.6978, -14.9307,  -6.3989, -23.4625,  12.4930,  18.2824,\n",
       "                          6.0941,  11.5789,  10.9695,   2.7424,   3.9612,  19.1966,  23.1578,\n",
       "                         34.4319,  34.4319,  35.9555,   8.2271,  17.6730,  -7.9224,  28.3378,\n",
       "                         32.6037,  32.9084],\n",
       "                       [ 18.4834,   9.9526,  12.0853, -19.9052, -19.4313, -21.8009,   0.4739,\n",
       "                          3.0806,   2.3697,  -4.7393,   7.8199,  -9.2417,   8.7678,  14.2180,\n",
       "                         11.6114,  21.5640,  22.7488,  23.6967,   9.4787,  12.7962,  13.9810,\n",
       "                         13.2701,  10.1896,   9.2417, -29.8578, -28.1990, -30.3317, -18.4834,\n",
       "                        -16.3507, -10.1896],\n",
       "                       [ 12.7892,   5.0154,  10.2815,  24.8262,  18.3062,  15.0462,  20.8139,\n",
       "                         18.0554,  17.5539,  29.3400,  28.5877,  23.8231, -21.8169, -13.2908,\n",
       "                        -16.8016,  -7.5231, -18.0554, -19.0585,  -7.7739, -14.7954, -14.2939,\n",
       "                        -32.0985, -31.0954, -30.8446,  -3.7615,   1.7554,  -2.2569, -24.8262,\n",
       "                        -24.8262, -21.3154],\n",
       "                       [-11.6068,   1.7857,   0.0000,  -3.2737,   2.9761,   2.3809,  16.6662,\n",
       "                         20.8327,  22.3208,  25.8921,  25.5945,  29.1658,  26.4873,  19.3447,\n",
       "                         18.4518, -38.0941, -34.8204, -36.9037, -29.7610, -18.7495, -24.9993,\n",
       "                        -31.2491, -32.1419, -33.9276,  -0.5952,  -9.5235, -10.4164, -27.9754,\n",
       "                        -25.5945, -26.4873],\n",
       "                       [ 20.4200,  16.9643,   9.7388, -40.2117, -38.6410, -39.2693, -33.6145,\n",
       "                        -33.3003, -36.4419, -26.0748, -27.3314, -26.3889,  25.4465,  24.5040,\n",
       "                         20.7342, -10.3671, -11.3095, -16.9643,  19.1634,  19.7917,  17.2785,\n",
       "                         26.7031,  32.9862,  37.6985,  32.9862,  32.9862,  37.0702,  13.8228,\n",
       "                         14.7652,   5.0265],\n",
       "                       [ 28.4508,  16.2999,  21.3381, -32.0071, -24.5981,  -8.0018,  12.4472,\n",
       "                         19.5599,  16.8926,   4.7418,  -5.6309,   1.1854,  30.8217,  30.2289,\n",
       "                         20.4490, -29.9326, -26.9690, -27.2653, -11.8545,   0.8891,  24.3017,\n",
       "                        -21.6344,  -7.7054,   8.5945,   1.1854,  -8.0018, -20.7453, -32.3035,\n",
       "                        -30.5253, -37.6380],\n",
       "                       [-23.8833,   8.7806,  -3.8635,  -8.0782, -31.9615, -42.4982,  26.3419,\n",
       "                         21.0735,  17.2100,  26.3419,  30.5566,  30.9078,  44.2544,  44.6056,\n",
       "                         44.6056, -39.3372, -40.3909, -42.1470,  35.4737,  31.9615,  15.4539,\n",
       "                        -26.6931, -24.5858, -38.6348,   0.3512,   8.7806,  23.8833, -17.2100,\n",
       "                        -19.6686, -22.4784],\n",
       "                       [-35.4072, -31.5509, -29.4475,   8.0630,   2.1034,   4.2068, -40.6656,\n",
       "                        -41.0162, -41.0162, -23.8385, -23.8385, -22.0857,  32.6026,  31.5509,\n",
       "                         33.6543, -44.8724, -44.5219, -44.5219,   6.6608,   5.6091,  13.3215,\n",
       "                         12.9709,  10.5170,   7.3619,  22.7868,  22.4362,  22.0857, -12.2698,\n",
       "                         -5.6091,   0.7011],\n",
       "                       [ 13.5994,  14.7568,  12.7314,  15.3355,  15.3355,  17.3610,  35.5900,\n",
       "                         35.5900,  36.4580,  -0.8680,  -1.7361,  -1.7361,   9.2592,   9.5485,\n",
       "                         11.5740, -33.8539, -34.1432, -31.5391,  -5.2083, -10.9953,  -5.4976,\n",
       "                         36.7474,  31.8284,  36.7474,  22.5692,  23.1479,  25.4627,  -2.8935,\n",
       "                         -2.0254,  -0.8680],\n",
       "                       [-37.7265, -37.7265, -38.0664, -27.8700, -27.5302, -26.1706, -32.2885,\n",
       "                        -33.3081, -34.3277,  17.6737,  15.9743,  13.2553,  38.4063,  37.7265,\n",
       "                         37.7265, -41.8051, -41.1253, -41.1253, -40.1057, -39.4259, -39.7658,\n",
       "                        -43.1646, -43.1646, -43.1646,  12.2356,   9.8565,   8.1571,  -2.0393,\n",
       "                         -2.7190,  -3.3988],\n",
       "                       [  7.7878,   6.4334,   6.7720, -39.6160, -39.6160, -39.9546,  -5.7562,\n",
       "                         -5.0790,  -4.4018,  43.0020,  43.0020,  43.0020,  17.6071,  17.6071,\n",
       "                         17.9457, -11.5124, -11.1738, -10.8352, -42.6634, -42.6634, -42.6634,\n",
       "                        -33.1827, -34.1985, -36.2301,  42.3248,  42.6634,  43.0020,  37.5844,\n",
       "                         37.5844,  37.5844],\n",
       "                       [  6.5734,   2.8580,   7.7166,   2.5722,  -0.5716,   6.2876,  18.0054,\n",
       "                         20.0060,  28.0084,  -1.4290,   2.2864,   2.2864,  -0.5716,   7.7166,\n",
       "                         11.4320,  -1.4290,   0.2858,   2.0006,  -4.8586,  -7.4308,   1.1432,\n",
       "                         12.0036,   6.8592,   2.5722, -30.2948, -28.5800, -30.0090, -36.5824,\n",
       "                        -34.8676, -35.4392],\n",
       "                       [-18.2743, -19.0253, -24.5327,  30.0400,  29.5394,  29.5394,   6.0080,\n",
       "                          6.7590,   4.0053, -23.2810, -24.5327, -21.2783, -22.7803, -19.7763,\n",
       "                        -17.7737,  -0.5007,   1.7523,  -3.5047,  14.7697,  16.2717,  13.2677,\n",
       "                        -31.7924, -31.0414, -32.0427,  10.0133,   4.2557,   5.5073,  10.5140,\n",
       "                          9.7630,  10.0133],\n",
       "                       [ 37.3903,  36.3612,  36.3612, -43.9078, -43.5648, -43.5648, -42.5357,\n",
       "                        -42.1927, -42.5357,  11.6630,  11.3200,   9.9479, -21.6109, -19.8957,\n",
       "                        -18.8667, -13.0351, -15.7794, -16.8085,   4.4594,  10.6339,  16.4654,\n",
       "                          9.6048,   9.2618,   8.5758,  43.5648,  43.2218,  43.5648, -22.2970,\n",
       "                        -23.3260, -23.3260],\n",
       "                       [ 15.2485,  16.6603,   9.8833, -24.0022, -17.7899, -16.6603, -23.4374,\n",
       "                        -20.0489, -24.5669,   2.5414,   0.5648,   8.4714, -29.3674, -29.0850,\n",
       "                        -31.3440,  30.2145,  28.5203,  31.0617, -24.0022, -12.9894, -22.5903,\n",
       "                         25.6965,  21.4608,  28.5203,  30.7793,  31.0617,  35.8621,  18.0722,\n",
       "                         10.4480,  16.3780],\n",
       "                       [ -5.5491,   5.8014,   6.8103, -26.9889, -25.7277, -25.4755,   6.5580,\n",
       "                          9.8371,   8.0714,   2.2701,  -6.8103,   6.0536,  32.0335,  27.2411,\n",
       "                         32.0335,  16.1429,  16.1429,  17.4041,   5.0447,   6.5580,   2.0179,\n",
       "                          4.7924,   7.5670,   8.3237, -29.7635, -30.7724, -30.2679, -18.6652,\n",
       "                        -13.3683, -19.4219],\n",
       "                       [ 23.8763,  23.8763,  25.8388, -14.3912, -19.2973, -24.2034,   4.2520,\n",
       "                          3.2707,   0.6541, -17.6620, -16.6807, -17.9890,   4.9061,   7.5227,\n",
       "                          6.2144,  23.8763,  22.5681,  22.8951, -26.1659, -26.1659, -26.8200,\n",
       "                         41.5383,  41.2112,  41.2112,  -0.9812,  -2.9437,  -4.5790,  21.5868,\n",
       "                         15.6995,  18.9702],\n",
       "                       [ 19.7742,  17.1723,  16.3918,  -7.0250,  -5.9843, -11.4482, -15.8714,\n",
       "                        -14.8306, -14.3103,   2.0815,  10.4075,   5.4639, -33.3039, -33.0437,\n",
       "                        -33.0437,  19.7742,  17.9529,  13.7899, -15.3510, -13.7899, -18.9936,\n",
       "                         -2.8621,   7.2852,  -1.0407,  -6.5047,  -2.8621, -11.9686,  13.2695,\n",
       "                         12.7491,  11.4482],\n",
       "                       [ 17.0296,  20.7316,  24.1869,   7.8978,   1.4808,   4.4425,  -4.4425,\n",
       "                         -9.3786,  -5.9233, -10.6126, -14.8083, -15.3019, -30.8507, -31.5911,\n",
       "                        -30.3570,  18.7572,  22.7061,  22.2125,  -1.9744, -10.3658,  -2.2212,\n",
       "                          9.6254,   6.1701,   5.4297,   8.3914,   4.4425,   6.4169,   1.7276,\n",
       "                         10.1190,   6.4169],\n",
       "                       [-22.6467, -20.4784, -15.4190,  30.1153,  30.3562,  30.5971,  11.3233,\n",
       "                         11.0824,  12.5280, -17.3464, -15.4190, -19.5147, -15.9009, -18.7919,\n",
       "                        -20.9602,   0.7228,  -1.2046,   3.8548,  16.1418,  14.9372,  19.0329,\n",
       "                        -29.1516, -30.1153, -27.9470,  -9.1550,  -3.6138,  -4.3366,  11.0824,\n",
       "                          9.1550,   7.9504],\n",
       "                       [  8.1335,   5.0835,  -5.4224, -42.3621, -42.7010, -42.7010,  23.3839,\n",
       "                         18.6393,  21.6894,  25.4173,  29.8229,  30.1618,  41.6843,  42.3621,\n",
       "                         43.0399,  20.3338,  21.3505,  26.4340,  37.9565,  37.6176,  38.2954,\n",
       "                          5.7613,   5.7613,   5.4224,  -5.7613,   9.8280,   7.1168,  42.7010,\n",
       "                         42.3621,  43.0399],\n",
       "                       [ 38.1907,  36.1448,  33.4169, -41.9416, -41.9416, -41.6006,  43.3056,\n",
       "                         43.3056,  43.3056,  23.8692,  25.9151,  18.4134,  10.5706,  19.7773,\n",
       "                         18.7544, -28.3021, -24.8922, -16.7084,  -7.8427,  -0.6820,   8.8657,\n",
       "                         -3.7509,  -1.0230,  -0.6820,  20.8003,  21.4823,  21.4823, -27.2791,\n",
       "                        -29.6660, -26.2561],\n",
       "                       [-42.1838, -40.8656, -41.1952,   3.2956, -13.5120,  -3.9547, -31.6379,\n",
       "                        -33.2857, -30.6492, -30.6492, -33.9448, -22.4102,   9.8868,  -1.9774,\n",
       "                          5.6025,  14.8303,  12.1938,  20.1032,  19.1146,   6.2617,   2.3069,\n",
       "                         28.3423,  27.3536,  20.7624,  17.7963,   7.2503,  22.7397,  40.2065,\n",
       "                         39.8769,  39.5474],\n",
       "                       [-43.6961, -43.3547, -43.3547,  11.2654,   7.5103,   7.8516, -15.7033,\n",
       "                        -16.3860, -15.3619,  35.1617,  34.4789,  35.1617,  26.6273,  26.9687,\n",
       "                         26.2859,  -7.8516,  -9.5585,   1.7069, -10.2413, -12.6309, -13.6550,\n",
       "                        -15.7033, -18.7757, -21.8480,  29.6997,  29.6997,  29.0169, -28.6755,\n",
       "                        -26.2859, -12.9723]], size=(27, 30), dtype=torch.qint8,\n",
       "                      quantization_scheme=torch.per_channel_affine,\n",
       "                      scale=tensor([0.3048, 0.2797, 0.2805, 0.3047, 0.2370, 0.2508, 0.2976, 0.3142, 0.2964,\n",
       "                       0.3512, 0.3506, 0.2893, 0.3399, 0.3386, 0.2858, 0.2503, 0.3430, 0.2824,\n",
       "                       0.2522, 0.3271, 0.2602, 0.2468, 0.2409, 0.3389, 0.3410, 0.3296, 0.3414],\n",
       "                      dtype=torch.float64),\n",
       "                      zero_point=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                       0, 0, 0]),\n",
       "                      axis=0),\n",
       "               Parameter containing:\n",
       "               tensor([-43.9846, -42.9427,  37.7914, -43.9967,  41.5277,  24.1090, -41.9118,\n",
       "                        41.3414,  34.4136, -44.6021, -43.2827,  -8.5413, -42.9074, -39.7934,\n",
       "                        43.9355, -40.7316, -43.0528, -43.8158, -40.6154,  40.1160,  40.7604,\n",
       "                        43.7532,  38.7281, -42.4603, -41.9696,  43.8568, -43.6694],\n",
       "                      requires_grad=True)))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (conv): Conv1d(\n",
       "    8, 10, kernel_size=(3,), stride=(1,)\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (batchnorm): Identity()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(\n",
       "    in_features=30, out_features=27, bias=True\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp32_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 29.8405,  15.0377,  27.4908],\n",
       "        [  4.9343,   0.4699,   8.2238],\n",
       "        [-26.0811,   9.8685,  -9.1636],\n",
       "        [ 11.0433,   3.2895,   5.6391],\n",
       "        [  6.1091,   1.6448,   0.7049],\n",
       "        [-20.2069, -15.5077, -13.3930],\n",
       "        [ 15.9776,  15.5077,  13.8629],\n",
       "        [ -9.6335,  -7.5189,  -9.1636]], size=(8, 3), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.23496443033218384,\n",
       "       zero_point=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.state_dict()[\"conv.weight\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('general_slu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5661c73bf5f4ce6179e3148e3c825b6832fd4cb82045a10b114db5b9548c77c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
